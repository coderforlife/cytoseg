===Example for Segmenting Mitochondria:===

(Input and training images for this example are included in the svn download.)

Parameters used in this example:
 * Input images folder (data that is to be processed): data\example\input
 * Output folder: output
 * Training images folder: data\example\train_images
 * Training segmentation folder: data\example\train_seg

(You will have the test data for this sample if you checked out via svn.)

Example (for Windows):
<code>
svn checkout http://cytoseg.googlecode.com/svn/trunk/ cytoseg-read-only
cd cytoseg-read-only
cd cytoseg
cd testing
mkdir output
python run_pipeline_test.py data\example\input output --trainingImage=data\example\train_images --trainingSeg=data\example\train_seg  --voxelTrainingLowerBound=*,*,* --voxelTrainingUpperBound=*,*,* --voxelProcessingLowerBound=*,*,* --voxelProcessingUpperBound=*,*,* --contourTrainingLowerBound=*,*,* --contourTrainingUpperBound=*,*,* --contourProcessingLowerBound=*,*,* --contourProcessingUpperBound=*,*,* --accuracyCalcLowerBound=*,*,* --accuracyCalcUpperBound=*,*,* --labelConfigFile=settings3.py --voxelWeights=0.0130,0.00064 --contourListWeights=7,1 --contourListThreshold=0.8 --step1 --step2 --step3
</code>

Example (for Linux):
<code>
svn checkout http://cytoseg.googlecode.com/svn/trunk/ cytoseg-read-only
cd cytoseg-read-only
cd cytoseg
cd testing
mkdir output
python run_pipeline_test.py data/example/input output --trainingImage=data/example/train_images --trainingSeg=data/example/train_seg  --voxelTrainingLowerBound=*,*,* --voxelTrainingUpperBound=*,*,* --voxelProcessingLowerBound=*,*,* --voxelProcessingUpperBound=*,*,* --contourTrainingLowerBound=*,*,* --contourTrainingUpperBound=*,*,* --contourProcessingLowerBound=*,*,* --contourProcessingUpperBound=*,*,* --accuracyCalcLowerBound=*,*,* --accuracyCalcUpperBound=*,*,* --labelConfigFile=settings3.py --voxelWeights=0.0130,0.00064 --contourListWeights=7,1 --contourListThreshold=0.8 --step1 --step2 --step3
</code>


In this example, the result stack will be written to output\voxelOutput\blobs\resized

To view the results superimposed on the original images, view the result stack in the folder output\voxelOutput\blobs\composite

===Example Result:===

Here is the result image stack from output\voxelOutput\blobs\composite

http://cytoseg.googlecode.com/svn/trunk/cytoseg/docs/mito_example_animated.gif

Note: there is a 30 pixel border around the image that is not processed. It has been cropped from the animated stack above.









==Practical Usage Guide==

You can run all three steps at once as in the example above (using --step1 --step2 --step3), but it takes some time to get through all of them. Sometimes you'll want to break things down more and run the steps separately to experiment.


===Step 1===

Processing input data can take a long time, so you probably want to start by process just a small part of it to see how well it works and adjust parameters. The step 1 (specified with --step1) just classifies the input data. You can make the input data small or use --voxelProcessingUpperBound and --contourTrainingLowerBound to set what subvolume of the input data you want to process. You can run step 1 over and over by itself adjusting parameters to see what the effect is on the data in the voxelOutput folder.


===Step 2===

Step 2 (specified with --step2) will classify the training image data. This is a step that needs to be done before step 3 will run. It classifies the training data in the same way that step 1 classifies the input data.


===Step 3===

Step 3 finds contours, classifies them, and generates 3D blobs. This step usually runs much faster than steps 1 and 2 because it does not involved classification of every voxel. It just involves classification of contours pairs. (There are far fewer contour pairs than voxels.) Assuming you have run step 1 and step 2, and you are adjusting --contourListWeights or --contourListThreshold=0.8, you only need to run step 3 to get the change.





