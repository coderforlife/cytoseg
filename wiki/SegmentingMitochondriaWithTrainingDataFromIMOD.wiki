Instructions under construction (August 2011)

Using command line on linux system:

==Training data==

This process requires a training data set. In the training data, structures that we are interested in must have been outlined in IMOD. You choose how much training data you want to use. More training data (i.e., more manually traced structures) typically makes the process more accurate. In our example we'll refer to this training data set:

/folder/Guttman_3month_wt.preali.mrc (the training data file)

/folder/Gutmann_mito.mod (the corresponding model file)

You'll also have a full dataset that you want to process automatically. We call this originalData.mrc in this example. This file can be (but does not have to be) the same as the training data file.


==Creating data image stack==

Convert your image data to an 8bit tif stack:
<code>
mrcbyte originalData.mrc byteData.mrc
</code>

Where origialData.mrc is the 3D image you have traced in IMOD and byteData.mrc is the name of the output file you want to use.


Convert your data to a tif stack
<code>
mkdir /dataFolder
mrc2tif byteData /dataFolder/file
</code>

==Creating training segmentation image stack==

You'll need an IMOD model where you have traced mitochondria existing in the data. This will serve as training data.

Convert your IMOD model file to a bitmap form:

Using this command
<code> imodmop -color model data output </code>
model: model file
data: data file that goes with the model (mrc format)
output: output file (mrc format)

Here's an example:
<code>imodmop -color /folder/Gutmann_mito.mod /folder/Guttman_3month_wt.preali.mrc trainingseg.mrc</code>

For the example, you can look at the output with:
<code> 3dmod trainingseg.mrc </code>

Convert the output mrc file from the last step to tif's with the command mrc2tif

Here's an example, first we are creating the "/trainingSegTiffs" folder as a folder to place our files.
<code>
mkdir /trainingSegTiffs
mrc2tif trainingseg.mrc /trainingSegTiffs/file
</code>

Use convert command (a command from Image Magick) to convert the stack to 8 bit

For example from inside the folder with the tif's (/trainingSegTiffs in this example), you can run this to do the conversion:

{{{
mkdir folderFor8bitFiles
ls *.tif | xargs -r -t -I FILE convert FILE -type Grayscale -depth 8 folderFor8bitFiles/FILE.8bit.tif
}}}

==Running the script==

Make sure you have python installed according to instructions for installation at cytoseg.googlecode.com

You'll need python to run the scripts.

Download this file with the python scripts http://cytoseg.googlecode.com/files/cytoseg_mito_example.zip

You can download from the command line with:
<code>
wget http://cytoseg.googlecode.com/files/cytoseg_mito_example.zip
</code>

Unzip the file
<code> unzip cytoseg_mito_example.zip </code>

At your command line, go into the cytoseg/testing directory

<code>
cd cytoseg
cd testing
</code>

Create and output folder:
<code>
mkdir outputFolder
mkdir outputFolder/cytoseg_data
</code>

Next we'll use the sbfsem_batch_voxels_test.py command.

In general, the command is used like this:


python sbfsem_batch_voxels_test.py input output --trainingData=test1 --trainingSeg=test2 --trainingLowerBound=X1,Y1,Z1 --trainingUpperBound=X2,Y2,Z2 --processingLowerBound=X1,Y1,Z1 --processingUpperBound=X2,Y2,Z2


input: the input folder with a stack of 8bit data image files (We created this in the "Creating data image stack section" above.)

output: toplevel folder for output of the process (We created this with the mkdir command above.)

--traningData specifies the folder with training data (can be the same as input)

--trainingSeg specifies the folder with 8bit segmentation bitmap stack (We created this in the "Creating segmentation image stack" section above.)

--trainingLowerBound specifies X1,Y1,Z1 corner of training data

--trainingUpperBound specifies X2,Y2,Z2 corner of training data

--processingLowerBound specifies X1,Y1,Z1 corner of input data to be processed

--processingUpperBound specifies X2,Y2,Z2 corner of input data to be processed


For our example, the particular command would be:

<code>
python sbfsem_batch_voxels_test.py /dataFolder outputFolder --trainingData=/dataFolder --trainingSeg=/trainingSegTiffs --trainingLowerBound=0,0,0 --trainingUpperBound=100,100,100 --processingLowerBound=0,0,0 --processingUpperBound=100,100,5
</code>



During the process, new folders and files will be created in the output folder you specified.

(Inside of the output folder, go to voxelOutput/mitochondria/composite to view your output in a convenient colorized form. This is useful for checking if the output looks correct.)

Inside of the output folder, voxelOutput/mitochondria/resized has a grayscale image of your output that can be thresholded with a program such as ImageJ to identify the structures of interest. Next, convert this output to IMOD format.

Use tif2mrc to create segmentation.mrc from the tif's in the resized folder.

==Converting autosegmentation output into IMOD model==

<code> imodauto -h 100 segmentation.mrc outputlines.mod </code>

Then, you want to open it with 3dmod:

<code> 3dmod intput.rec outputlines.mod </code>

Next you'll want to mesh this by clicking: Image > Model View... then... click Edit > Object... then Meshing and Mesh All. (this is equivalent to running "imodmesh outputlines.mod outputlines.mod"). 

Now you can save and go back to the command line. And type:

<code> imodsortsurf  outputlines.mod outputlines.mod </code>

.. this sorts the contours by the surface # they have been meshed into. And finally it sounds like you want to type:

<code> imodsortsurf -s outputlines.mod outputlines.mod </code>




=Acknowledgements=
Thanks Andrew for the instructions to convert into IMOD format.


=Etc=
Note for new users: use copy and paste heavily to speed up your work with the command line.